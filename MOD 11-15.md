# MOD 11
## Anomaly Detection
### NetFlow Search Query Basics
<img width="1999" height="1394" alt="150ccb94-fa9c-4c90-a77f-6fc344e98d94" src="https://github.com/user-attachments/assets/eac69f8a-ca97-4f17-93b3-a9a2ba49f229" />

#### Understanding NefFlow Data in SecOnion
- Network devices (such as routers or switches) using protocols like **NetFlow v5**, **NetFlow v9**, or Internet Protocol Flow Information Export (**IPFIX**), send data to a collector.
- For Security Onion, that collector is **Filebeat** (specifically collected through Filebeat’s NetFlow module). 

#### NetFlow Data Ingestion
- The Filebeat NetFlow module listens on a configured port ([UDP] or [TCP]) for incoming raw NetFlow data from these devices.
- When NetFlow records arrive, the Filebeat NetFlow module **normalizes and enriches** them into one of the nine data types described above, saving the data into **netflow.log**.
- It then forwards the normalized records to Elasticsearch for long-term storage and analysis.

#### Log Generation and Processing
- Filebeat processes the incoming NetFlow data using a pipeline.
- For this lesson’s version of Security Onion, the pipeline is **filebeat-7.17-1-netflow-log-pipeline**. 
- The ingested NetFlow data is broken into hundreds of fields, depending on the NetFlow version and the values present in the data.
- Each field has an associated data type.
- For example, netflow.destination_ipv4_address is an ip type, and netflow.destination_transport_port is an integer type.

- The pipeline performs field extraction, parsing, and normalization to create structured records with predefined fields.
- Common fields that may be used to perform NetFlow queries include, but are not limited to, the following:
  - event.action: netflow_flow
  - event.dataset: netflow.log
  - event.module: netflow
  - flow.id: (random assigned id)
  - input.type: netflow
  - service.type: netflow
  - netflow.destination_ipv4_address
  - netflow.destination_transport_port

### NetFlow Search Queries
- View entire count of NetFlow data: `* | groupby event.dataset`
- Show Source IP with highest occurance: `* | groupby event.dataset netflow.source_ipv4_address`
- Add an additinal column for desination IP" `* | groupby event.dataset netflow.source_ipv4_address netflow.destination_ipv4_address`
- View source port numbers: `* | groupby event.dataset netflow.source_transport_port`
- Create a column of destination ports: `* | groupby event.dataset netflow.source_transport_port netflow.destination_transport_port`

#### NetFlow Queries Using Kibana
- Query for NetFlow data: `event.dataset: "netflow.log"`
  - Add the following fields to the output: `source.ip`, `destination.ip`, `source.port`, `destination.port`
- Refine search to identify IP addresses using port 0: `event.dataset: "netflow.log" and (netflow.source_transport_port: 0 and netflow.destination_transport_port: 0)`
- Search for flows larger than .095MB or larger than 100,000 bytes: `event.dataset: "netflow.log" and network.bytes > 100000`





















  
