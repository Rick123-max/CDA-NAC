# MOD 6
## Operationalizing Threat Intelligence
### Cyber Threat Intelligence Overview
- At its heart, intelligence is the science and art of understanding the enemy.
- As a discipline, intelligence is as old as warfare itself.
- Commanders have striven to predict the actions of their adversary, whether on a kinetic battlefield or in a futuristic cyberwar.
- Understanding the enemy’s capability and intent is the only way to make informed decisions on one’s own tactics to employ in response.
- Understanding the Operational Environment (OE) — the **conditions**, **circumstances**, and **influences** that affect the employment of capabilities — is paramount to making sound decisions in both offensive and defensive engagements.
- Traditionally in military intelligence, this refers to such things as the enemy’s **firepower**, **aggressiveness**, or **infrastructure** available to resupply their troops.
- In the cyber domain, direct correlations can be made to “traditional” intelligence. The product of these correlations forms CTI.

#### Intelligence in the Cyber Domain
- CTI is analyzed, actionable information, derived **internally** or **externally**, that aids an organization in **identifying**, **assessing**, **monitoring**, and **responding** to cyber threats.
- Because the cyber domain is now a major battlefield for crime, activism, and espionage, CTI has become increasingly essential to cyber defense.
- Relying on current and historical attack knowledge, an analyst can leverage CTI to prepare for future attacks on a defended terrain.
- Almost every tenet of traditional military intelligence can be applied to the cyber domain, not just in a military application.
- The cyber intelligence landscape is vast.
- It is unique in that there are thriving communities in both private and public sectors.
- The **private**, or **open-source**, intelligence community can be found in many different forums; **social media**, **vendor websites**, **blogs**, and **subscription services** are good examples.
- The government intelligence community, simply known as the “Intelligence Community” (**IC**), is less available to the public.
- Both these communities provide valuable resources to an analyst on a Cyber Protection Team (CPT).
- In fact, the CPT construct has an entire work role — the All-Source Analyst (ASA) — dedicated to interfacing with both the IC and open-source intelligence communities.
- Thanks to its countless devices and large intelligence communities, cyber, in general, has no shortage of “data.”
- Analysts use applications to collect data, they store data on servers, and they sift through telemetry data generated by anything that can ship a log.
- It is this data, or information, that eventually becomes intelligence.

#### Data vs. Intelligence
- Joint Publication 2-0, Joint Intelligence, Executive Summary, states the following about information (or “data”) vs. intelligence:
  - **_“Information on its own may be of utility to the commander, but when related to other information about the operational environment and considered in the light of past experience, it gives rise to a new understanding of the information, which may be termed ‘intelligence.’” _**

- In other words, analysis is what separates information from intelligence.
- For cyber defense, analysis is what makes data about threats in the cyber domain become CTI.
- For example, a Domain Name System (**DNS**) lookup for example[.]com is a piece of data.
- Further analysis may indicate that the domain is registered to Threat Actor, LLC, and can be tied to an ongoing espionage campaign.
- That extra analysis step is what makes data useful intelligence.

### The Intelligence Cycle
- Analysts need to understand the application and cyclical nature of CTI to be effective in countering active and future threats on a network.
- CDAs who are part of a CPT are not expected to perform formal intelligence analysis, but they are the consumers and, in some cases, collectors of intelligence.
- Maintaining realistic expectations and knowing what can be provided to the IC increases mission effectiveness throughout the execution of an operation.
- CTI follows the Intelligence Cycle, in which CDAs play an active role.
- Figure 6.1-1 illustrates the six steps of the cycle: **Direction**, **Collection**, **Processing**, **Analysis**, **Dissemination**, and **Feedback**.
  ![eed5e1d5-9f2e-481b-90d8-763547cd5c61](https://github.com/user-attachments/assets/a039dfb1-cadd-4fd9-be57-6a05e7358973)

#### Direction
- CTI analysis is always based on requirements.
- The **first step** of the Intelligence Cycle is to **define a clear requirement or question** for which intelligence should provide an answer.
- Often, for external intelligence, this requirement or question is submitted to an intelligence analyst in the form of a **Request for Information (RFI)**.
  - Uses for intelligence are numerous, so RFIs may ask a wide variety of questions.
- CDAs likely are most concerned with obtaining or collecting tactical intelligence for immediate use defending a network.
- Sometimes, a CPT may be employed to answer or collect information on intelligence requirements given by a higher tasking authority.

#### Collection
- The collection of cyber intelligence is typically the **process of collecting data from networks useful in tracking a threat**.
- However, it may come in other forms as well, such as reading a news article for political or economic information pertaining to a mission partner’s organization or viewing data from an open honeypot provided by researchers on the internet.
- At this point in the cycle, this is just data and not yet intelligence.
- **Collection is not a one-time effort**.
  - It comes in cycles of its own.
  - For example, a CDA may find a suspicious Internet Protocol (IP) address thought to be Command-and-Control (C2) communication to a malicious server.
  - The next cycle of collection on that data might be identifying what domain resolves to that address, followed by a cycle of collecting certificate information on that domain.
  - The cycle continues until enough data is collected to meet the requirement defined prior to collection.

#### Processing
- An analyst should not overlook the importance of processing data to be usable.
- A CDA’s analysis platform should be flexible and configurable enough to view a multitude of different data types in a normalized way.
  - For example, collected logs from firewalls may have different formats, depending on their type or brand.
- It is more useful if a CDA can process the log data to conform to a standard format than if they must manually interpret and compare the logs separately.
- The creation of **visualizations** also falls into the Processing step.
  - **Visualizing data** can greatly **assist a CDA or ASA in identifying trends** and **answering questions proposed** to the intelligence process as a whole.

#### Analysis
- **CTI analysis is based on requirements**.
- Without a requirement, the analysis has no question to answer.
- This is the step in which **data becomes intelligence**.
- Questions asked, or requirements presented, in the initial step of the cycle (Direction) are answered using analysis.
- The Analysis step is distinct from Processing.
  - Whereas the Processing step is usually automated or involves only manipulating data, analysis is done exclusively by a human.
  - This is where a CDA interprets the data that was collected and processed in previous steps.

#### Dissemination
- Intelligence is a shared commodity.
- It should be shared with the entity that requested the information, and it is often shared with a larger community of intelligence analysts.
- CDAs should concern themselves with this step because the format and completeness of the collected data and analysis directly affect the value of the dissemination of intelligence.
- ASAs are leveraged in the step to disseminate intelligence back to the IC.

#### Feedback
- The last step of the Intelligence Cycle is Feedback.
- Did the analysis properly answer the requirement?
  - This is a question that CDAs should answer if requesting or analyzing intelligence.
  - If the intelligence fails to meet the requirement, a new cycle is started in which the error is corrected or intelligence gaps are identified more fully.

### Levels of Intelligence
- When dealing with consuming or collecting intelligence on a network, intelligence comes in different forms and at different levels, depending on requirements given to an analyst.
- Consider the following examples:
  - The political motivations of a threat group.
  - A list of APTs assessed to have the capability and intent to target a mission partner’s network.
  - Domains tied to a specific APT for use in an Intrusion Detection System (IDS).
- Each example represents a different level of intelligence that a CPT may request or be required to fill.
- The three levels, or **taxonomic categories**, of intelligence are **strategic**, **operational**, and **tactical**.
  - The first example listed above represents strategic intelligence; the second, operational intelligence; and the third, tactical intelligence.

#### Strategic Intelligence
- Attacker **motivations**, **politics**, or **trends** that **inform an organization’s policy decisions and planning** represent the **strategic** level of intelligence.
- Often, strategic intelligence is the **trigger for the start of an operation** or a **change to network architecture**.

#### Operational Intelligence
- Attacker **Tactics**, **Techniques**, and **Procedures** (**TTP**) and **capability** are typically viewed as **operational** intelligence.
- This intelligence **informs collection plans** and **mission-planning efforts** **prior to an incident response or hunt engagement**.

#### Tactical Intelligence
- **Immediately applicable intelligence**, such as Indicators of Compromise (**IOC**), **antivirus signatures**, or **IDS rules**, fall into the **tactical** level of intelligence.
- This intelligence is **most useful for CDAs** on a mission **during on-network engagements and retroactive investigations**.

### Strategic Intelligence
- Cyberspace does not exist in a vacuum.
- Strategic intelligence deals with **external**, and **often global**, **influences** on the cyber threat landscape.
- The following are example intelligence requirements that pertain to the strategic level of intelligence:
  - Based on new political developments in the region, what threat groups may be motivated to attack the mission partner’s network?
  - Which trends in cybersecurity indicate a threat to the mission partner’s attack surface?
  - Should active cyber threats dictate a change in collaboration software for the organization?

- As illustrated in these examples, **strategic-level intelligence** deals with **threat actor trends and motivations** and **informs policy decisions**.
- Strategic-level questions have **real financial impact** and may **inform the movement of defense efforts**.
- This intelligence can assist all analysts by **giving context to defense efforts**, even at the most basic and direct levels.

#### Application of Strategic CTI
- During a CPT mission or planning of such a mission, **strategic intelligence** plays an important role in **comprehensively understanding the network environment**.
- In fact, a subset of strategic intelligence called **warning intelligence** is one of the **three main triggers for CPT employment**. (The other two triggers are **campaign planning and detected malicious cyber activity**.)
- Additional characteristics of strategic CTI are as follows:
  - Strategic CTI provides a comprehensive view of the target or attacker, to include motivations, resources, and capability.
    - This can come in the form of target profiles, briefings, or reports.
  - Strategic CTI seeks to predict future attacks based on trends and other forms of intelligence collection.
  - Strategic CTI provides input to planning and policy development.
    - Sometimes it can inform policies on mission partner networks as a by-product of a mission’s final report.
- This all adds up to the explanation of what a CDA should be worried about — or, more specifically, whom a CDA should be worried about — when defending a network.

#### Who Is the Enemy?
- Strategic intelligence boils down to one big question: **“Who is the enemy?”**
- This is not a question to completely craft collection plans around, but it is an **intelligence requirement** that is **fundamental to every decision made** when it comes to **employing CPTs** and other defense teams.
  - For example, assume that a specific organization’s most likely enemy, based on strategic-level intelligence, is motivated by financial gain and is known to sell stolen intellectual property.
  - Knowing nothing else about the network or organization, how would that inform mission planning or network architecture decisions?
    - If the organization in this example is attacked by the most likely enemy, the following is true:
      - Data exfiltration of intellectual property is likely.
      - The servers with the most valuable information are most likely the targets.
      - The attack comes from outside the organization (so the enemy is not an insider).
- These assumptions and intelligence most likely lead the organization to invest in greater protection of the sensitive data or servers and possibly to consider a standalone network for valuable intellectual property.
- The above conclusions from the example intelligence would likely drive follow-on requirements to narrow down TTPs or IOCs for analysis.

### Attribution to the Enemy
- **Attribution is not the job of a CDA**.
- However, attribution is an **important aspect of CTI**.
- Knowing (or assessing) who attacked, or will attack, a network is essential to policy makers and planners.
- Having no idea who attacked a network makes it impossible to track campaigns or anticipate future attacks from any particular entity.
- Furthermore, CDAs can use existing attribution information to more quickly identify and counter a threat actor on a defended network.
- Even though attribution is not the responsibility of a CDA, it is **important to know how CDAs contribute to the process** and **how attribution decisions are made by the IC**.
- By knowing the steps and information needed to attribute an APT, CDAs can distinguish between the threat groups more easily. 

#### Threat Group Tracking
- The concept of a threat group is often misleading.
- What makes up a threat group or APT?
  - Sometimes they are tied and attributed to government agencies, sometimes they are crime organizations, and sometimes they are synonymous with the malware they are known to use.
  - An even more perplexing question is: How is tracking a threat group possible? Why don’t APTs simply change their tactics after every attack?
- **Threat groups**, as a concept, are a **conglomerate of tendencies and identifiable tactics** that **allow for researchers and intelligence analysts to identify patterns**.
  - These patterns are possible, and necessary, for threat groups to operate.
  - After all, when APTs are thought of as someone’s job, patterns make sense.
  - For example, a fast-food restaurant does not serve different hamburgers if someone calls in sick. Threat groups operate similarly.
  - To achieve repeatable success with a team of operators, a repeatable process needs to be implemented. That repeatable process becomes a trackable threat group.
  - In fact, most tracked threat groups are an abstraction and primarily equate to a set of instructions that humans follow, not to the humans themselves.

- Attribution of APTs to organizations that exist outside cyberspace is more challenging than identifying patterns and tactics.
- **Motives**, **politics**, and other **non-technical attributes** need to be analyzed to make that kind of determination. 
- **Tracking threat groups, from a CDA perspective**, is important because it **creates sets of TTPs** that can be **searched** and **planned** for on a network.
- Without having a predictable set of behaviors to search for, analysts are left with virtually infinite combinations of TTPs to plan for.

#### What’s in a Name?
- **Naming APTs or threat groups** is necessary and is a **standard practice for every organization** that tracks them.
- Being able to identify a group with a **short name** is obviously **preferable** to using something like “that group that uses phishing and password spraying and is assessed to be from East Asia.”

- However useful the naming of threat groups may be, every entity that tracks these groups names the groups based on their own criteria.
  - Vendor A’s tracking of a group is not necessarily the same as Vendor B’s.
  - A common misconception of the CTI community is that direct equivalencies exist between threat groups tracked by different vendors.
  - There is a reason for the lack of equivalency: **perspective**.
  - For example, consider the following scenario.
    - Imagine two CTI entities looking at the same attack: one is a vendor who specializes in host-based antivirus, and another is a vendor specializing in firewalls.
    - They each have their own telemetry and data on the incident.
    - It is reasonable to think that the antivirus vendor focuses on the malware signatures on the host and the firewall vendor has a deep understanding of the C2 traffic leaving the network.
    - The use of the same malware in a follow-on attack, but with modified C2 patterns, may cause the firewall vendor to attribute these two attacks to different groups but the antivirus to continue attributing to the original group.
  - This is an unrealistically simplified example, but it illustrates how viewing threat groups from different perspectives causes attribution of APTs to diverge over time.
  - Zooming the example out even more, consider entities that deal in CTI but are not vendors.
  - Such entities as cybersecurity vendors are quite interested in detectable attributes that can protect their customers’ networks, but entities like government agencies tend to be more interested in attribution to humans or other governments.
  - This tends to make attribution by government agencies lean more toward nontechnical attributes of a threat group.
  - CPTs have to take all these perspectives into account when determining which TTPs and APTs to target.
- Keeping this naming and tracking perspective in mind, security researchers and intelligence analysts use a standard framework for attribution decisions: **Malware**, **Infrastructure**, **Control Server**, **Telemetry**, **Intelligence**, and **Cui Bono**, or **MICTIC**.

### MICTIC Framework
#### Overview
- CDAs need to know what type of information is helpful for the IC to have to make attribution decisions so that it can be collected while on mission.
- It is also important to know that a single artifact is often not enough to make official attribution decisions.
- The MICTIC Framework, as described in Timo Steffens’ book Attribution of Advanced Persistent Threats: How to Identify the Actors Behind Cyber-Espionage, is a standard method to tie attack campaigns and attributes to threat groups or sometimes even declare a brand new threat group discovered.
- The MICTIC Framework comprises six evidence categories of an attribution decision:
  - **Malware**
    - Intelligence analysts can track and attribute APTs based on the malware they employ on victim networks.
    - This may seem obvious. However, taking things a step further, some APTs outsource the authoring of malware for their own use.
    - That relationship between the author and the entity that employs the malware is also good evidence for attribution.
    - It may also assist in identifying nefarious relationships between malware authors and multiple APTs.
    - Evidence that CDAs can provide includes **malware samples** and **sandbox reports**.
  - **Infrastructure**
    - The pathways that C2 takes to and from victim networks provide a good indication of who is attacking a network.
    - In fact, some larger nation-state APTs have teams with the sole purpose of setting up infrastructure.
    - By investigating things like **domain name registration** and **IP address ownership**, a pattern may emerge that points to known bad actors.
    - Evidence that CDAs can provide includes **packet captures**, **domain names**, **IP addresses**, and **certificate information**.
  - **Control server**
    - Typically, the Control Server evidence is seized by law enforcement or government agencies from attacker-owned or -rented servers.
    - Certain things like language **settings**, **certificates**, **user accounts**, and **saved files** are quite useful in positively identifying not only threat groups but also human operators.
    - Evidence that CDAs can provide includes **packet captures to C2 servers from victim networks**.
  - **Telemetry**
    - Information logged from **inside victim networks**, such as **command-line logs**, **IDS alerts**, and **antivirus messages**, provide analysts with a **treasure trove of information** useful for attribution.
    - For example, evidence of attacker interactivity on a network that happens only during working hours in Moscow and stops on Russian national holidays might be a good indication the threat group is based in Russia.
    - Evidence that CDAs can provide includes **log information ingested into analysis platforms** and **crew logs indicating observed attacker behavior**.
  - **Intelligence**
    - Of the six evidence categories in the MICTIC Framework, **Intelligence** and **Cui Bono** are the two that **CDAs have little to do with**.
    - **Governments** and **researchers** have the ability to **aggregate many pieces of information** and **collect intelligence that may indicate an attacker's identity** outside a victim’s network.
    - **Intelligence** may be from a **human source**, **intercepted communications**, or any other **traditional intelligence source**.
    - **Cui Bono**
      - An **analysis** of **who would benefit** from the attack **politically**, **financially**, or otherwise.

#### MICTIC Application
- By analyzing each evidence type and comparing it to a known set of APTs, researchers and intelligence analysts can make informed attribution decisions.
- Some attributions are made with more confidence, whereas others may be made with less confidence but still show ties and similarities between attacks.
- Again, making attribution decisions is not a CDA’s job.
- It is, however, highly important from a strategic standpoint for leaders to assess who has attacked, or might attack, in the future.
- Also, **attribution** allows for an analyst to **more effectively plan for**, or **quickly react to**, active **intrusions** on **mission partner networks**. 


### Operational Intelligence
- **Strategic intelligence**, by definition, is **long term** and, as illustrated in the previous section, **takes considerable effort to track and apply**.
- Once stakeholders and analysts are aware of the strategic intelligence for their operating environment, more granularity is needed for operationalizing that intelligence.

- **Operational intelligence** is **higher-level information** on **campaigns** and threat actor **TTPs**.
  - It deals with more **immediately applicable intelligence** to **mission planning and operations**.
  - For example, **strategic intelligence** may **indicate an APT** to initiate a hunt mission for, but **operational intelligence** provides the **TTPs** and **capabilities** of that APT to plan the mission around.

- As each level of intelligence is explained, strong connections between each level are evident.
- For example, operational intelligence on TTPs of attackers is not possible without first using strategic intelligence to attribute and anticipate the adversary.
- Likewise, tactical intelligence relies on operational intelligence to determine what directly pertains to a defended terrain.

- Operational intelligence is **high-level**, but **short-term**, **intelligence**.
- It does not get into IOCs or specific commands an attacker might run on a victim network, but it does **deal with fluid topics like TTPs**.
- It is **observable** and relates to **specific attacks or attack campaigns**, as opposed to the broader approach that strategic intelligence provides.

#### Intelligence in Operations
- Attacker capabilities and intent are the cornerstones of operational intelligence.
- After identifying who the enemy is, the next logical questions asked are “What can the enemy do?” and “What does the enemy want?”
- Based on intelligence and data collected from previous attacks, repeated patterns related to TTPs and actions on objectives by the attacker can give analysts in CPTs insight into what to expect while on mission.

#### Attacker Capabilities
- The capabilities of an APT directly relate to the resources they have available.
- Do they create their own custom malware? Are they able to purchase hundreds of domains on the internet? Do they enhance their operations with their own intelligence collection?
- APTs with the most resources will obviously have the most advanced capabilities.
- When defending against or hunting for attackers with advanced capabilities, it is reasonable to assume that traditional methods of detecting malicious activity on a network will not work.
  - As an example, for a well-resourced APT, antivirus will most likely be ineffective. 
- Similarly, detecting attackers with advanced capabilities is resource intensive.
- Resource intensive might mean it is **expensive**, requires **deeper analysis**, or takes **more time to detect**.
- This creates an imbalance if a highly capable attacker targets a resource stretched organization.

#### Attacker Intent
- Knowing or assessing what an attacker is attempting to accomplish on a victim network makes defending against that attack possible.
- Operational intelligence seeks to determine what an attacker or attack campaign is trying to accomplish based on strategic intelligence indicators.


### Applied TTPs
- Dealing with capabilities and intent goes only so far when planning the defense of a network.
- Knowing, for example, that an attack campaign indicates that an APT is using open-source malware and is altering valuable information on victim networks indicates attacker intent and capabilities.
  - However, this gives only vague information.
- There are more intelligence requirements to be met when planning a defense.
  - Specifically, how does the attacker operate?
- Consider the following, for example:
  - How does the attacker typically gain initial access?
  - What method is usually used for persistence on a host?
  - Will the CPT be able to see clear text communications in network traffic?
  - How much time passes between initial foothold and actions on objective?

- These intelligence requirements all point to TTPs.
- Knowing and mapping TTPs of an APT give an analyst something concrete to build their defense around.

- Using such tools as the **MITRE ATT&CK® framework**, intelligence analysts can effectively communicate operational level intelligence to a CDA in the form of TTPs.
- In essence, an **ATT&CK matrix describing an APT is that threat group’s fingerprint**.
- After all, as discussed early in this lesson, threat groups are merely an abstraction of linked TTPs.

- **Combining APT capability**, **intent**, and **known TTPs** can provide a CPT with the following information:
  - The amount of resources needed to defend a network.
  - Where on the network will be targeted.
  - How the attacker will attempt to accomplish their goal.
- Absent specific IOCs and signatures, this is enough information for a CPT to plan an entire operation around. 


### Tactical Intelligence
- In cyber defense, tactical intelligence is low-level and short-lived intelligence that allows direct response to cyber threats.
- As detailed in the sports example above, it is also the **easiest intelligence type for an attacker to alter**.
- Its perishable nature requires that it is refreshed often, but accurate and timely tactical intelligence can prove invaluable in an **active situation** or **retroactive investigation**.

#### Uses for Tactical Intelligence
- In a cyber defense application, tactical intelligence can be applied directly to an analysis platform and other tools that a CDA uses to interact with an environment.
- Most notably, it is conveyed in the form of IOC.
- Other forms of tactical intelligence are exact commands run on a system by an attacker or other observable tendencies like usernames or network traffic signatures.
- Tactical intelligence has two main uses: **active hunting or engagements** and **retroactive investigations**.
  - Using it during an active engagement can assist CDAs in directly countering a threat.
  - Tactical intelligence during retroactive investigations can provide evidence that malicious activity occurred.

#### Active Hunting
- Using IOCs, IDS signatures, and other readily applicable intelligence on a network during an active intrusion or hunt can deliver quick wins for an analyst.
- By using intelligence on active campaigns or attacks currently happening in cyberspace, relevant indicators can be ingested into an analysis tool for low-effort discovery and countering of attackers on a network.

- However, challenges exist with tactical intelligence in an active environment.
- One challenge is that tactical indicators are easy for attackers to change.
  - By accumulating a large number of IOCs from online repositories or internal intelligence databases, the processing and storage overhead is often not commensurate with the value of the data.
- Another challenge is that commonly, by the time tactical intelligence becomes processed and disseminated, it has already become stale.
  - Also, related to that point, many attackers change their identifiable tactical level signatures between every attack.

#### Retroactive Investigations
- Using known IOCs and other observables when reviewing logs for an investigation of a confirmed attack can be highly valuable.
- The inherent issues with tactical-level intelligence applied to active situations do not exist with retroactive forensics.
- In fact, stale IOCs may be more useful than current information.
- Looking back in time using known indicators may reveal more and provide for a more complete picture of the incident because the more time that passes, the more likely that information will be available for intelligence analysts to disseminate.


### RFI Process
- The process of requesting information or intelligence from the IC or a commercial intelligence team may be formalized, depending on the assigned unit, command, or organization.
- Typically, this function is performed by the ASA in a CPT, but the act of initiating a requirement may be the responsibility of a CDA.
- Although CPTs have assigned intelligence personnel, certain research and information gathering tasks still fall on CDAs.
- This section introduces the process of submitting an RFI and how to interpret its response.

#### The RFI Submission
- To receive specific intelligence about any particular topic or mission, a request must be submitted to the IC.
- Typically, submitting something to the IC means that an intelligence analyst assigned to a higher command does research on the topic and submits a response.
- Stating “Submitted to the IC” really means that it is given to another analyst or team of analysts to query for information on another system.
- If the intelligence requested does not exist already to answer a requirement, the Intelligence Cycle begins, with the RFI serving as the direction.
- Understandably, the entire Intelligence Cycle may take some time to complete, so it is important to be flexible but up front if the due date is swiftly approaching.

#### RFI Criteria
- The request itself should meet certain criteria.
- The IC expects certain items, as follows, to be included in order to respond with a useful answer.

#### Requestor/Requestee
- The RFI should indicate who requested the information, along with good contact information for any follow-up questions or clarifications needed by the intelligence analysts working the request.
- An alternate contact for the request is also helpful, especially in time-sensitive requests.

#### Request
- A request is a straightforward, simple question or requirement that needs to be answered.
- There is an art to crafting a request that leads to an appropriate response.
- After all, intelligence analysts are not mind readers.
- CDAs should be as precise and direct as possible and include an example of the response they are expecting.

#### Due Date
- Depending on where the RFI is addressed, it could be competing with a long list of other requests. Due dates are used to prioritize competing requests.

#### References
- For intelligence analysts to expedite research, it is important that they know which resources have already been checked.


## Threat Actor Research
### CTI Models and Requests for Information
#### CTI Models
- CTI data includes **tools**, **exploitation strategies**, **victims**, **strategic priorities**, **technical and organizational mechanisms**, **cyber infrastructure information**, and other factors that build an understanding of threat actors.
- CTI models are used by cybersecurity personnel to organize data about those threat actors.
- By gathering, processing, and studying CTI, CDAs can make decisions more quickly and accurately. 

- Once CTI is obtained, it can be organized into a CTI model.
- Three common CTI models are as follows:
  - **MITRE ATT&CK**: A knowledge-based CTI model that has users **match TTPs with sequential stages** in the ATT&CK matrix.
  - **Cyber Kill Chain®**: A linear series of stages, derived from a similar model used by the military, that depicts the **steps in a cyber attack**.
  - **Diamond Model**: A model in which, as the name suggests, **incidents are depicted as a diamond**.
    - Unlike other models, the Diamond Model **emphasizes relationships** between components of an attack.
- Although these three models are not the only CTI models used in cybersecurity, they represent some of the most commonly used and prolific ones.
- Professionals use other models, such as Find, Fix, Finish, Exploit, Analyze, Dissemination (**F3EAD**); the Observe, Orient, Decide, Act (**OODA**) loop; and the **Intelligence Cycle**, to organize information as well. 

- **TTP** is a catchall term for describing the **behaviors and tools of a cyber threat actor**, and TTPs **represent a significant topic** when discussing CTI models.
- By identifying the TTPs of an (APT) or other attacker, security analysts may better understand the threat as well as predict future cyber attacks and advise on appropriate mitigating controls.

#### Requests for Information
- An RFI is a term that describes the process of acquiring information about intelligence from intelligence analysts.
- An ideal RFI should contain at least the following aspects:
  - The names of those who requested the information and a backup contact in the event the primary person is not available.
  - A precise description of the information needed.
    - If the request is too broad or vague, the returned intelligence might not cover the depth of information needed.
  - A list of sources that has been checked for information prior to creating the RFI.
    - This helps the analyst avoid receiving information they already possess.
  - A due date. 
- Although these are general requirements, the RFI may change, depending on the specific scenario.

### MITRE AT&CK Matrix
- In 2013, MITRE introduced the ATT&CK matrix, a knowledge-based CTI model.
- This utility allows users to categorize threat actor behaviors based on real-world data.
- By understanding and using the ATT&CK matrix, analysts gain a greater perspective of attacker behaviors and become better prepared for mapping defensive controls in their network.
- Additionally, ATT&CK provides a common language for communication between internal security teams and other personnel outside the organization. 

- To use the ATT&CK matrix, open the ATT&CK website, https://attack.mitre.org, in a web browser.
- Matrices for mobile devices and Industrial Control Systems (ICS) also exist, but for this lesson, the Enterprise Matrix is used.
- The matrix is updated periodically as the cybersecurity landscape changes; as of early 2022, the matrix has 14 Tactics categories.
- A tactic, which is the goal of an adversary’s action, is the broadest component in the matrix.
- Each tactic includes several associated Techniques.
- A technique represents the actions taken by a threat actor to accomplish their tactic.
- Each technique may have associated Sub-Techniques, as a greater degree of granularity may help categorize some malicious behaviors.
- Finally, each technique or sub-technique contains Procedures, which are specific examples of how an adversary carries out their technique or sub-technique.
- Below is the hierarchy within the ATT&CK matrix:
  ![45668aeb-a7c4-4089-9338-26ce2613efa5](https://github.com/user-attachments/assets/88c79efb-55bb-4ccb-b36a-54efa972d9bf)

#### Bandook and ATT&CK
- By cybersecurity standards, the Bandook Remote Access Tool (RAT) is an ancient piece of malware.
- Having emerged in 2007, this malware is written in C++ and Delphi and has been used in cyber attacks against various sectors globally.
- Although its use subsided for some time, such attacks as Operation Manul (2015) and such groups such as Dark Caracal (2017) have brought back some of its popularity.

- Bandook is primarily distributed via phishing emails containing an infected Microsoft Word document with a trojan embedded inside.
- To increase the chances of successful execution, the malicious document instructs the victim to enable macros.
- Once enabled and opened, the malicious macros are downloaded to the victim’s machine.
- Finally, the macro executes a PowerShell payload that downloads and executes the Bandook backdoor disguised as Internet Explorer.
- At that point, the Command-and-Control (C2) server, controlled by the attacker, can issue commands to the Bandook backdoor.
- Examples of attacker capabilities include taking **screenshots**; **uploading**, **downloading**, and **executing files**; and **processing shell** **commands**. 

### Cyber Kill Chain
- The Cyber Kill Chain®, first released by Lockheed Martin Corporation in 2011, is a CTI model that uses a seven-stage timeline, placing a greater emphasis than the ATT&CK matrix or the Diamond Model on the processes and sequence of events in an attack.
- The objective of using the Cyber Kill Chain is to first identify the current stage of the attack and then attempt to disrupt the current “link” of the chain.
- This causes a cascading effect on the adversary.
- An important, additional distinction of the Cyber Kill Chain is its focus on APTs.
- The stages of the Cyber Kill Chain are illustrated in Figure 6.2-2 and summarized as follows.
  ![5ddbc0c0-3276-4713-8f2f-56d7afc2c9f9](https://github.com/user-attachments/assets/3ba8ed58-8153-4c97-a230-2765398c763b)
1. **Reconnaissance**: The first stage of the Cyber Kill Chain, involving multiple processes of information gathering, both Open-Source Intelligence (**OSINT**) and possible **social engineering**.
2. **Weaponization**: A pre-attack stage in which the adversary composes the exploit and vulnerability.
3. **Delivery**: The stage in which the threat actor initiates the first step of the attack. The exploit is delivered to the target via email, Server Message Block (SMB), physically, or via other methods.
4. **Exploitation**: The stage in which the exploit has been delivered and the adversary executes the attack on the target systems.
5. **Installation**: The stage in which the system has been compromised and the attacker places persistence malware on the target.
6. **C2**: The stage in which the adversary establishes communication between a malicious server and the victim’s systems. This allows for backdoor commands and communications to be exchanged.
7. **Actions on Objectives**: The final stage of the Cyber Kill Chain, comprising any activities after the initial attack, aiming to further the interests of the adversary. This stage is relatively open ended. 

- The use of the Cyber Kill Chain is linear, focusing on the attack narrative.
- When using the Cyber Kill Chain, it is important to have a clearly defined stage for any event in a cyber attack, as detecting activity in one stage of the Cyber Kill Chain allows network defenders to prepare for the next actions of the adversary.
- Even if the attack has taken place in the past, using the Cyber Kill Chain structure provides guidance to forensic personnel in determining the previous malicious activities. 

### Diamond Model
![fc88a68e-0e47-41c5-bd0b-580c1082f2fa](https://github.com/user-attachments/assets/1e854a4b-e5d2-4c61-97a7-e7c5a278740c)

- A third CTI model is the Diamond Model of Intrusion Analysis, or, more simply, the **Diamond Model**.
- According to the Diamond Model, every cyber incident may be depicted as a diamond with four “points,” as illustrated in Figure 6.2-3 and described as follows:
  - **Adversary**: The threat actor responsible for the cyber attack or any other malicious activity.
  - **Capabilities**: The TTPs associated with the adversary.
  - **Infrastructure**: The adversary’s assets, both physical and logical, that are leveraged in their operations.
  - **Victim**: The target of attacks, which may be organizations, individuals, or specific vulnerabilities.
- Unlike the ATT&CK and Cyber Kill Chain models, the Diamond Model emphasizes the relationships of each component in the model.
  - The relationships of the four points of the diamond may be analyzed, and greater insight into the threat actor may be gained.
  - These points may be converged into a single phrase:
    - **“An [ADVERSARY] uses a [CAPABILITY] over a(n) [INFRASTRUCTURE] against a [VICTIM].”**

- This is useful, as it illustrates how exactly an attacker employs their skills against a certain victim.
- The **vertical** and **horizontal** axes are important parts of the Diamond Model.
  - The **vertical axis**, connecting the Adversary and Victim components, depicts the **sociopolitical axis**.
    - This axis shows the **reasons and goals for the adversary’s taking action against the victim**.
  - The **horizontal axis**, connecting the Capabilities and Infrastructure components, depicts the **technical axis**.
    - This axis shows the **resources and technological** aspects of the attack.
  - Plotting data into the Diamond Model, unknown information can present itself.
    - For example, knowing the IP address of a C2 domain may indicate the identity of an adversary.
    - The more points of the diamond that have information, the easier it is to infer knowledge of the missing pieces. 

- This gives analysts the ability to look at future attacks and see how behaviors of the past can indicate potential future actions.
- The Diamond Model also offers the ability to discover knowledge gaps, as plotting data into the model can help with highlighting missing information more clearly.
- Finally, the Diamond Model can be incorporated into mitigation planning and security frameworks. 

- Using the same scenario from the Cyber Kill Chain section, a Diamond Model can be created and filled with information, as the following example shows:
  - **Adversary**: Currently unknown.
  - **Capabilities**: Phishing, FTP exploit, logic bombs, persistence malware, credit card information theft.
  - **Infrastructure**: C2 server (IP and registered domain name), email addresses.
  - **Victim**: A financial institution, vulnerable FTP server.
- In the above example, the Adversary component of the Diamond Model is unknown.
- However, by using the information gathered about the capabilities, infrastructure, and victim, it can be reasonably surmised that the adversary is a group of attackers who aim to create financial gain for themselves.
- Through forensic examination of attacker email addresses, domain names, coding styles, IP addresses, and more, this adversarial persona may be further defined.  

### Comparing CTI Models
![94406738-e054-4695-9677-c68c89e5e7dd](https://github.com/user-attachments/assets/1a93d62b-efbd-4fd3-be1c-d3505c6206f4)


## MITRE ATT&CK FRAMEWORK
### ATT&CK Matrix | Techniques
- **Reconnaissance**: Techniques that involve adversaries actively or passively gathering information that can be used to support targeting (for example, staff/personnel, infrastructure).
- **Resource Development**: Techniques that involve adversaries creating, purchasing, or compromising/stealing resources that can be used to support targeting.
- **Initial Access**: Techniques that use various entry vectors to gain an initial foothold within a network (for example, a spear-phishing link).
- **Execution**: Techniques that result in running attacker-controlled code on a local or remote system (for example, PowerShell).
- **Persistence**: Techniques used to maintain persistent access to a system (for example, logon scripts).
- **Privilege Escalation**: Techniques used to gain higher-level privileges on a system or network (for example, process injection).
- **Defense Evasion**: Techniques used to avoid detection (for example, Dynamic Linked Library [DLL] side-loading).
- **Credential Access**: Techniques for stealing credentials, such as account names and passwords (for example, Kerberoasting).
- **Discovery**: Techniques used to gain knowledge about the system and internal network (for example, network sniffing).
- **Lateral Movement**: Techniques used to enter and control remote systems on a network from the already compromised host (for example, Pass the Ticket).
  - Attackers typically have to pivot through multiple machines — usually the weakest link in the chain of machines — to ultimately reach their end objective.
- **Collection**: Techniques used to gather information relevant to following through on the attacker’s objectives (for example, input capture).
- Command and Control (**C2**): Techniques attackers may use to communicate with systems under their control; often disguised to look like normal Hypertext Transport Protocol (HTTP) traffic (for example, domain fronting).
- **Exfiltration**: Techniques used to steal data from a network (for example, exfiltration over web service).
- **Impact**: Techniques used to disrupt availability or compromise integrity by manipulating business and operational processes (for example, firmware corruption).
  - Impact is the result on a system after the attacker accomplishes their ultimate goal and is the most recently added tactic.


## Threat Mitigation
### Cyber Kill Chain
#### Phase 1: Reconnaissance
- The first phase of the kill chain, Reconnaissance, covers initial information gathering before the adversary begins an attack.
- Reconnaissance can be leveraged in an attack cycle in several ways, from identifying potential access vectors to determining the most viable target for conducting an attack.
- When attackers survey a target, they look for as much information as possible, such as network technologies used and services exposed.
- Network technologies include unique **protocols**, **hardware**, and **software** standards such as **optical**, **broadband**, and **radio**, which all provide varying access vectors.
- Examples of services that may be exposed to publicly available networks or even the internet include the following:
  - File Transfer Protocol (**FTP**)
  - Simple Mail Transfer Protocol (**SMTP**)
  - Remote Desktop Protocol (**RDP**)
  - Telnet

- Examples of key data elements that an attacker can leverage that may be gathered by initial reconnaissance methods include the following:
  - Enumeration (list, identify, and research) of internet-facing assets.
  - Internet Protocol (IP) ranges and associated domain names, ports, and services.
  - Implemented technologies or application platforms.
  - Leaked credentials or keys.
  - Leaked documents, logs, configuration files, and backup files.

- One type of attack reliant on the Reconnaissance phase is spear-phishing.
- Through reconnaissance, the adversary can gain knowledge through press releases and an organization’s or employee’s social media presence.
- This can aid attackers in identifying persons to target and topics to address ineffective phishing messages that are likely to trick victims.

- Threat actors can aggregate actionable data about a target entity through the use of Open Source Intelligence (OSINT) collection.
- **OSINT** is the method of **gathering information through publicly available sources** on the internet. 

- Three types of information gathering exist in security:
  - **passive**
    - Passive OSINT techniques are those that do not engage or interact with the target entity.
    - The requirement of these methods is that no artifacts or traces of the queries are left behind for the target to discover.
    - Techniques of passive reconnaissance include the following:
      - Collecting public information and records regarding network or person.
      - Aggregating unprotected social media information.
      - Recovering previous versions of the target's website (for example, via WayBack Machine).
      - Querying such search engines as Google or Shodan for exposed devices or services belonging to the target.
  - **semi-passive**
    - Semi-passive OSINT techniques directly interface with the target but in a way that is plausibly deniable and blends in with standard traffic.
    - Techniques may include interacting with a target's website or other online services but blending into the white noise of normal traffic and performing all actions from a non-attributable IP/domain.
    - If the attacker is detected in a later phase of the Cyber Kill Chain by the target, all evidence of these methods would be non-attributable.
  - **active**.
    - Active OSINT techniques are methods that directly interface with a target and can leave an identifiable signature.
    - An example of an active OSINT technique is a port scan.
    - Conducting a port scan rapidly queries available ports on a target and can provide a great deal of information to aid in an attack.
    - However, many modern security systems are configured to detect such activity and flag it as malicious.

#### Phase 2: Weaponization
- After identifying a viable entry into a target network, an attacker enters the Weaponization phase, in which they develop their attack with the goal of ensuring an initial point of presence in the victim’s network and enabling additional access.
- The activities that an attacker performs in this phase occur on a workstation or network controlled by the attacker, so a defender does not have a real-time view of the attacker's actions during this phase.
- The Weaponization phase may include an attacker crafting an enticing social engineering ploy to compel an employee to open an attachment or click a malicious link.
- Other times, the attacker may require a custom-crafted payload; in these cases, the Weaponization phase occurs when the parameters of this malware are **defined**, **compiled**, and **tested**.

- The Weaponization phase is informed by the results of reconnaissance.
- For example, with successful information gathering, a threat actor can determine the host endpoint protections in place in a victim's environment.
- At that point, upon compiling and testing their malicious payload, attempts can be made to evade that specific technology's detection.

- The Weaponization phase may take some time if there are special needs for the exploit or payloads that need to be developed.
- Advanced attacks may require research and development in an isolated lab environment prior to conducting an actual attack.
- Also, a series of unknowns exist when going into any remote cyber attack; even if the exploit works, a chance exists that the payload may fail and need to be reworked.

- To exploit an identified vulnerability in the target's network, an attacker uses private, custom, or open-source exploits.
- In any case, the actor needs to weaponize their tool to match the unique system and network architecture requirements of the target they intend to attack.
- In addition, they usually implement obfuscation techniques to evade network and host detection capabilities.

- There are no guaranteed defenses against some weaponization techniques, such as with a zero-day technique.

- Examples of weaponization techniques include the following:
  - **Obfuscate** (for **example**, **encrypt**, **encode**, or **reorder**) a malicious executable to evade antivirus (AV) detection.
  - **Modify** open-source exploits to target a specific target's IP and security configuration.
  - **Build** a novel exploit against a target device or platform (**zero-day**).

#### Phase 3: Delivery
- In the Delivery phase, an attacker attempts to circumvent any controls in the defended network to deliver their weaponized payload to their target.
- A host of TTPs exists that an adversary may use to deliver their exploit.
- The chosen TTP is dependent on information gained about the target from the Reconnaissance phase.
- For example, the attacker may identify a vulnerable web server in the target’s network and then deliver the exploit by sending specially crafted packets over the internet.
- Or the attacker may learn that their target regularly visits a certain website and therefore delivers their payload via a watering hole attack.
- Given the ubiquity of email, attackers most likely attempt to deliver their exploit via malicious attachment or to entice a user to click a link to prompt a malicious download via phishing. 

#### Phase 4: Exploitation
- The Exploitation phase takes advantage of an identified vulnerability in the target environment with the intent of triggering the attacker’s delivered code.
- The vulnerability could be technical and target a vulnerable application or Operating System (OS), or it could be non-technical and target the user.
- For a technical vulnerability, two exploit vectors generally exist:
  - **remote**
    - Remote exploits target network-enabled services and devices that are not properly patched or configured.
    - These exploits allow an attacker to achieve Remote Code Execution (RCE), where they can run code on a remote target.
    - Web servers, FTP servers, email servers, RDP, Server Message Block (SMB), and a host of other popular services all have been the target of RCE attacks.
  - **local**
    - Local exploits target local services and leverage attack methods to execute malware or escalate privileges.
    - An attacker needs to gain an initial foothold on their target to take advantage of a local exploit.

- Aside from the vector, exploits take advantage of three types of vulnerabilities:
  - **Public**: Publicly disclosed vulnerability that has an available patch.
  - **N-day**: Publicly disclosed vulnerability with no current patch.
  - **Zero-day**: Undisclosed vulnerability.

- The National Vulnerability Database (**NVD**) maintains a repository of publicly disclosed vulnerabilities alongside references that provide supplemental information related to the vulnerability, such as the **vendor advisory**, **technical details**, **workarounds**, and **mitigations**.
- Often, a vulnerability disclosure may lead to publicly available exploit code as attackers and security researchers analyze the vulnerability’s technical details or reverse-engineer the patch. 

- Undisclosed vulnerabilities (**zero-days**) have an inherently greater cost to exploit because they are **less readily available** and **difficult to discover**.
- Therefore, attackers exploit zero-days sparingly due to fear that the more they exploit zero-days, the more likely they are eventually detected.

#### Phase 5: Installation
- During the Installation phase, the attacker installs a Remote Access Trojan (**RAT**) or reconfigures a system to maintain persistence on a target machine.
- This way, should they want future access, an attacker does not have to repeat phases 1 through 4.

- To enable persistent access, an attacker must choose an appropriate technique that varies from target to target and may depend on their level of access.
- A normal user does not have the same privileges and access as a root or administrative user.
- Even the most adept attackers might have trouble picking the perfect approach for each situation.
- An attacker may choose to install malware such as a RAT.
- Alternatively, on a Windows machine, an attacker may simply add a remote desktop user if the service is available or leverage a similar technique with other remote management services, such as (WinRM).

- Non-malware-based installation on a Unix system could include adding an authorized Secure Shell (SSH) key to the target system, enabling the attacker to connect to the target remotely with SSH without needing a valid password.
- Additionally, many Unix systems come with Netcat, which can be used to open a port and listen for traffic.
- An attacker could daemonize (run in the background as a service) a Netcat connection on a given port, which provides the attacker on-demand Command and Control (C2).

- Because an attacker may want to maintain a presence for a long time, attackers try to masquerade their activities to make them appear legitimate or benign to users and security tools.
- Examples of masquerading include naming a RAT with a filename that matches the name or location of legitimate files or resources, adding a double extension in the filename to disguise the true file type (for example, .zip.exe), and modifying a malicious file’s metadata to match that of a legitimate file.

#### Phase 6: C2
- Regardless of the method of communication, the purpose of C2 is consistent: **maintain control of compromised assets to perform additional operations**.
- This requires three components:
  <img width="3334" height="776" alt="3d01eb95-23c4-41fa-bba0-3791b06fbd2a" src="https://github.com/user-attachments/assets/3880c7a0-61ac-4aa3-80e7-3c308920e23f" />

- Generally, C2 traffic conforms to one of two paradigms:
  - **scheduled**
    - Scheduled C2 generally involves an installed program or service that reaches out to an attacker-controlled resource for its management instructions.
    - This type of control requires the attacker to have procured or compromised another resource on the internet.
    - This C2 method through an outbound connection means that this type can be installed on devices that are not directly reachable from the internet (such as those behind a firewall).
  - **on-demand**.
    - On-demand C2 requires that the service or port be accessible to the attacker, which may not always be possible, depending on the network topology.
    - Installations that respond to on-demand C2 can include malware configured to listen on an otherwise-unused port or remote control services like RDP or SSH, if associated accounts have been created or compromised.

- The desirable attributes of a C2 channel are generally consistent and should include the following:
  - **Be Stealthy**: The data flow in the channel should be either hidden under encryption or obscured by mimicking normal network traffic through similar channels (or both).
  - **Be Indistinct**: The command source and victim machine should appear to be related so traffic between them does not stand out.
  - **Be Redundant**: The channel itself should be difficult to shut down or block if discovered.
- Rarely are all three attributes available to an attacker.
- For instance, access by SSH provides encryption, but SSH traffic from an unknown source through a network edge likely appears suspicious to network defenders.
- As with installation, knowing which C2 channel is appropriate for which environment is both an art and a science and might require an extensive amount of triage. 

#### Phase 7: Actions on Objectives
- If the attack was successful, the attacker then begins the next phase of the attack: Actions on Objectives.
- This phase is largely defined by the goal of the attacker’s campaign.
- During this phase, the attacker uses their C2 channel to control their target and achieve their purpose.
- Typical actions taken at this phase include **enumerating attached devices**, **credential harvesting**, **Active Directory (AD) compromise**, and **stealing sensitive files**.
- Extreme examples of next steps by threat actors in this final phase include disruption of network services and data destruction.
- Alternatively, the initially compromised host may just provide a pivot point to move laterally further into the target network.
- Depending on the objectives of the attacker, this phase may include direct “hands-on keyboard” interaction with the target. During this interactive portion of the attack, the attacker experiences a high risk of exposure; therefore, tradecraft is essential.
- Advanced Persistent Threats (APT) are skilled at hiding, whereas less-skilled attackers or those with a shorter timeline do not use stealth and may not care about being caught.

### Disrupting the Chain
- Each phase of the kill chain presents an opportunity for a defender to disrupt, deny, and degrade an adversary’s attack.
- If a defender can put a halt to an attack by enacting a mitigating control, it forces the attacker to either change tactics, move on to another target, or stop their attack.
- Ideally, an organization should strive to be a “hard target,” where the effort involved to penetrate their defenses convinces a would-be attacker to concentrate elsewhere.
- Furthermore, the earlier in the chain that a defender can detect and prevent an attack, the less impactful that attack is.
- All organizations wish they could have an endless budget and ability to hire and retain an outstanding security team to protect their networks.
- However, not all organizations are well equipped, in which case the organization needs to perform a proper terrain analysis and identify their key terrain.
- From there, the organization should put in the proper mitigating controls to thwart the attacker at each phase of the chain.
- A full rundown of how to perform a terrain analysis is beyond the scope of this lesson, but the next section examines a few examples of how to disrupt the chain at each phase.

#### Disrupting Reconnaissance
- Disrupting the Reconnaissance phase requires limiting the public exposure of information for an organization and its employees.
- The less an attacker can learn about a target through passive and active reconnaissance, the more difficult it is for them to craft their weapon.
- In addition, an organization that seems “boring” on the web is more likely to be passed over by an attacker than an organization that appears “flashy.”

- The most extreme defense is for an organization to have no web presence and to not allow their employees to share information about their roles or the company on social media platforms.
- For most businesses, however, it is a great benefit to have an online presence to advertise themselves, gain more business, and increase revenue.
- Therefore, it behooves an organization to find the appropriate balance between sharing too much and too little.

- There are sensible steps that an organization can take to combat passive reconnaissance.
- Some of these steps are as follows:
  - **Enforce a social media acceptable use policy**, which is an organizational policy that prescribes what information employees can share on the web (for example, social media profiles, blogs, wikis).
  - **Follow Operations Security (OPSEC) best practices** to prevent the adversary from observing or stealing sensitive or critical information.
  - **Restrict web crawlers**; that is, prevent indexing by search engine spiders, or limit their access to only certain web pages and content. 
- Inevitably, as an organization grows in size, it becomes exponentially more difficult to control the release of sensitive information.
  - Therefore, regular training of employees to be conscious of what they share online is needed, along with providing an appropriate reporting channel for employees to report concerns and potential violations.

- Whereas disrupting passive reconnaissance requires a human element, disrupting active reconnaissance typically takes a technical approach.
- Here an organization must try to limit their attack surface as much as possible and restrict an attacker’s ability to conduct scanning against their network.

- Some protective measures an organization can take to disrupt active reconnaissance are as follows:
  - Disable unused ports and services.
    - This limits the number of paths that an attacker can take to infiltrate a network.
    - Modify server error messages.
      - Reduce the amount of information that an attacker can glean from scanning.
    - Implement a firewall Intrusion Detection System/Intrusion Prevention System (IDS/IPS).
      - Provide early detection of scanning activity, and block connections from The Onion Router (Tor) and third-party Virtual Private Network (VPN) exit nodes.

#### Disrupting Weaponization
- It is impossible to stop an attacker from weaponizing their payload because this act occurs on the attacker's side.
- However, it is possible to defend against techniques used for weaponization. 

- The first and most effective defense against weaponization for an organization is to ensure that its systems are patched for known vulnerabilities.
- This prevents an attacker from coupling their payloads with known exploits.
- Patch management exponentially raises the difficulty for an attacker to penetrate an organization’s network by forcing them to research and develop novel exploits.
- An effective patch management process begins with having an accurate Asset Inventory Management System (AIMS), where version and patch information for each system and its components are stored and updated.

- In addition to patch management, an organization should create secure baselines, meaning that any unneeded capabilities should be disabled from the onset.
- For example, attackers commonly use Microsoft Office macros as a technique for weaponizing. An effective mitigation is to configure a system to disable macros as part of a secure baseline.
- Other configuration settings that should be modified or hardened include the following:
  - **Disabling browser plugins**.
  - **Disabling Microsoft Office add-ins**.
  - **Enabling behavior prevention on endpoints**, such as Attack Surface Reduction (**ASR**) on Windows 10.

- Weaponization, along with later phases in the kill chain, can also be disrupted with the addition of defensive tools.
- This helps an organization to create defense-in-depth.
- For many attackers, the act of weaponizing their payload is done with an automated tool, or weaponizer.
- Unless the attacker has the resources to spend in creating their own weaponizer, they likely use a publicly available one.
- Well-known, publicly available weaponizers include the Veil Framework, Social Engineering Toolkit, Burp Suite, and Metasploit.
- Generally, every weaponizer, even custom-made ones, leaves artifacts and patterns in their use that can be detected by an IDS or prevented by an IPS.
- Organizations should ensure that they regularly update the signatures for these security tools.

#### Disrupting Delivery
- Once an attacker has weaponized their payload, they deliver it into the targeted organization’s network.
- Numerous technical controls can be put in place to disrupt delivery, regardless of the vector used by the attacker.
- Similar to the Weaponization phase, organizations should invest in adding defensive layers with IDS and IPS tools on the host and network side.

- An effective mitigation to disrupt delivery by web is to employ web filtering via a secure web gateway or web proxy.
- Security technology has greatly improved for this control type over the years.
- Many solutions in this market today can statically and dynamically analyze web pages for malicious content and then make an informed decision to allow or disallow the traffic to an employee’s web browser. 

- Because email is such a popular delivery mechanism for an attacker, it is highly recommended that an organization put in measures to inspect emails before the messages make it to their intended recipient.
- One technique that attackers do to add legitimacy to their email phishing attacks is to spoof the sending address.
- To combat this, it is possible to configure email authentication methods like DomainKeys Identified Mail (**DKIM**) and Sender Policy Framework (**SPF**).
- A phishing email may contain a malicious attachment for the user to open or a Uniform Resource Locator (URL) for a recipient to click on.
- Solutions are available that can automatically detonate the attachment or URL in a malware sandbox and report the analysis.
- To combat malicious attachments delivered via email, an organization, if possible, should create an allowlist of acceptable file extensions and deny or strip any attachment that does not meet that criterion.
- It is also common practice for URLs to be sanitized to prevent employees from automatically clicking the links without first inspecting them or to even direct the link to an isolated web browser to prevent possible infection. 

- Organizations, particularly ones in air-gapped networks, should be prepared to defend against malware delivered physically via removable media (for example, Universal Serial Bus (USB), CD/DVD, or Secure Digital [SD] cards).
- The most effective approach to deter this threat is to disable the use of removable media altogether unless allowed through exception.
- When allowed through exception, it is recommended to check for the presence of malware by scanning the device on an isolated workstation prior to inserting it into the intended system.

#### Disrupting Exploitation
- The Exploitation phase occurs once the attacker’s malware has slipped through all the defenses.
- This is when the intent is to run the delivered code.
- Because most of this phase is dependent on the techniques used during the Weaponization phase, many of the same defenses apply.
- These defenses include **patch management**, **configuration of secure baselines**, and **addition of tools** that could help detect and prevent exploitation attempts.
- Those steps help mitigate against exploit attempts against the system, but what about exploit attempts against the user?

- For phishing attacks attempting to exploit a user, a critical defense is user awareness.
- Employees must be regularly trained so they know how to spot a potential phish, whether it comes from email, Short Message Service (SMS), web delivery (for example, a social media post with a malicious link), or some other medium.
- Part of the user awareness training must include a reporting mechanism to report potential threats.
- Although humans are well known for falling victim to phishing attacks and remain the most-used vector for delivery, they can also be one of the best sensors for spotting an attack.
- It takes only one employee from a pool of targeted employees to report the phishing attempt, which, in turn, brings attention to the phishing attempts that were missed.

#### Disrupting Installation
- Armed with a successful exploit, the attacker focuses on gaining persistent access, typically through the installation of a RAT or through reconfiguring the system and creating a backdoor.
- At this phase, a critical component to disrupting installation is to **limit user privileges as part of the system’s secure baseline**.
- Normal users should not be able to make registry changes or install new software.
- If possible, system administrators should **disable macros and PowerShell for Windows-based systems** and **confine users on Linux systems to chroot jails**.
- In addition, organizations should ensure that **monitoring is in place** to catch abnormal process activity via a User Behavioral Analysis (**UBA**) or Endpoint Detection and Response (**EDR**) engine.
- Examples of abnormal activity include the following:
  - Microsoft Word spawning PowerShell
  - Apache Tomcat spawning Bash
  - Java calling rundll32

- When an attacker’s malware is discovered or installation is prevented, if conditions permit, the malware should not be immediately destroyed.
- It is important to study it and understand its capabilities.
- Gathering Indicators of Compromise (IOC) related to the malware helps to find additional victims and put the necessary protections in place to disrupt future attacks and later phases of the kill chain by the actor.

#### Disrupting C2
- At the C2 phase of the kill chain, the actor has managed to install their chosen persistence mechanism and wants to open a channel to remotely manipulate the system.
- Usually, actors choose common protocols and ports to create this channel for two reasons: **to blend in with normal traffic** and **to avoid being blocked by network edge devices**.
- Therefore, the most common C2 protocols used by attackers are web ([HTTP/HTTPS]) and Domain Name System (**DNS**), as these are generally always open within a network. 

- All traffic leaving an organization’s network should be scrutinized for its destination and protocol.
- As in the Delivery phase, web filtering is an effective mitigation to prevent an attacker from setting up a C2 channel.
- Organizations should **configure clients to proxy their DNS and web requests** and **block domains and IP addresses that are known as bad**.
- In addition, it is highly recommended that a **proxy block connections to recently registered domains**, as threat actors frequently stand up new infrastructure to perform their attack.

- When possible, organizations should invest in Deep Packet Inspection (DPI) tools that break apart the header and analyze the content of network packets.
- DPI provides defenders with a more robust opportunity to detect and prevent threats by providing additional capabilities, such as the ability to do the following:
  - **Reconstruct delivered malware**.
  - **Identify potential data leaks**.
  - **Recognize protocol traffic over a mismatched port** (for example, DNS request over Transmission Control Protocol [TCP] port 80).

- Most attackers encrypt their communication channel using Secure Sockets Layer (SSL) or Transport Layer Security (TLS) protocols.
- As a result, organizations that do not add SSL/TLS decryption to their security stack are leaving an open door for an attacker to take advantage of.
- A drawback of decrypting traffic, however, is network latency because it adds processing time, so it becomes a balancing act for each organization to weigh the threat against the disadvantages of implementing any new control.

- Defenders can also disrupt encrypted communications by gathering and pivoting on the information contained in the SSL/TLS certificates used by the adversary.
- The approach here, which does not require DPI, is to fingerprint the SSL/TLS negotiation between an infected host and the attacker’s C2 infrastructure.
- One method of fingerprinting this negotiation is known as JA3.
- JA3 creates an MD5 hash based on the decimal values of bytes in certain fields of the Client Hello packet: **Version**, **Accepted Ciphers**, **List of Extensions**, **Elliptic Curves**, and **Elliptic Curve Formats**.
- Armed with this fingerprint, a defender can bolster their hunting to prevent future compromises or identify active ones.

#### Disrupting Actions on Objectives
- Once the attacker has set up their communication channel, they move toward completing their objective.
- This is the last opportunity that a defender has to disrupt their activity before serious impacts can be inflicted.
- Those impacts depend on the attacker’s intent, so defenders should try to understand the threat scenarios that they face before an attacker ever reaches this phase.

- Unless the attacker was lucky enough to immediately land on a system that meets their objectives, a typical goal for attackers is to further their access by elevating their permissions and moving more deeply into the victim’s network.

- For example, a bank would be concerned with an attacker who is financially motivated and intent on modifying wire transfers and bank accounts.
- The attacker may manage to phish a bank employee and compromise that employee’s workstation, but that may not be enough access for them to fully achieve their goals.
- They need to elevate their privileges and gain access to the system that handles such transactions.
- This is where proper **network segmentation** and **authentication controls** are a defender’s best defenses to disrupt the attacker at this phase.
- These controls at least slow the attacker down, increase their dwell time (the length of time an attacker is present on a victim’s network), and give the defenders more time to discover the adversary and eradicate them. 

- Even the most secured organization may have an attacker eventually reach this phase.
- It is critical for defenders to have **incident response playbooks** in place for the possibility of such an occurrence.
- Having a preplanned course of action helps to reduce the defender’s Mean Time To Respond (MTTR), which is the average time required to restore a system to an operational condition after learning about a cyberattack or intrusion.




# MOD 7
## Defensive Posture
### Undserstanding Defensive Posture
- **Defensive posture** is the _overall state of cybersecurity defenses for an organization and is determined by reviewing the entire picture of security within an organization_.
- This includes the following categories:
  - **Security policies**: All operating policies and how they relate to security, as well as security policy and procedures.
  - **Security training**: Security personnel training as well as entire organizational staff training.
  - **Security architecture**: All assets, asset configurations, and the network topology of an organization.
  - **Risk management**: Vulnerability management, risk analysis, and patch management.
  - **Security controls**: Physical and logical security controls to defend the organization.
  - **Security personnel**: The training and experience level of security personnel for an organization.
- Assessing defensive posture gives an overall idea of the security currently in place and efforts needed to ensure proper protection.
- Of the categories above, a **CDA should focus on security architecture**, **risk management**, and **security controls**.
- All other areas fall under the scope of organizational leadership and are handled at the organizational level.

#### Measuring Defensive Posture
- Organizational leadership is in charge of deciding the level of defensive posture of their organization.
- Leaders should work in conjunction with cybersecurity personnel to analyze all organizational aspects of security.
- Risks should be analyzed alongside all defensive measures in order for leadership to dictate the overall level of defensive posture.
- The MITRE (ATT&CK®) framework can be used to analyze defensive posture.
  - This process consists of reviewing all aspects of threats through the different sections of the ATT&CK matrix.
  - All areas from within the ATT&CK matrix are compared against defensive capabilities. 

- Analysis of these common tactics is performed in two ways.
  - The first way is from a high-level review, without a specific threat in mind.
    - This high-level analysis focuses on preventing or mitigating the overall threat of common adversarial tactics.
    - For example, high-level analysis of the common tactic of privilege escalation should ensure that mitigating controls exist to prevent general privilege escalation threats and monitor for the threat of privilege escalation occurring within the organization.
  - The second type of analysis is far more granular and is applied on a per-threat basis.
    - This level of analysis is used to review every aspect of a specific threat and ensure defenses are in place to help mitigate or eliminate the threat.
    - This is far more resource intensive and is generally prioritized for threats that pose extremely high risks to the organization.
- Another method for analyzing defensive posture is use of a Security Information and Event Manager (**SIEM**).
  - SIEMs can be used to gather an overarching picture of the defensive posture for the security architecture.
  - This picture can be gathered by parsing through logs and then generating searches that correlate many statistics about security operations.

- A defensive posture dashboard can provide defensive posture and architecture information at a glance.
- This dashboard typically includes the state of devices on the network, graphs and charts of key log and network activity, details from security assets, vulnerability metrics, alerts, and statuses of all potential incidents.
- One issue with this type of measurement is that getting a SIEM tuned to accurately provide the defensive posture can take significant time — even years — depending on the size and complexity of an organization.
- SIEM dashboards can be prone to false positives, so time and resources are required to tune dashboards to an adequate baseline to reflect the organization’s defensive posture.

#### Network Defensive Posture
- When performing Enable Harden functions while on mission, Network Analysts are primarily focused on strengthening the defensive posture of the network.
- Whereas Host Analysts are more concerned with specific controls and patches to strengthen the defensive posture of individual devices, Network Analysts must look at defenses from the network perspective. 
- When addressing overall defensive posture, a holistic approach must be taken.
  - However, Host or Network Analysts may create more specific dashboards that can be used to narrow the scope to just the host activity or network activity.  
- A network defensive posture dashboard should include **port**, **protocol and service information**, **IP** address information, **network traffic trends**, **anomalous network activity**, and **signatures or alerts specific to network traffic**

#### Defensive Posture and Cyber Threat Intelligence
- Knowing an organization is at risk from threats or threat actors alters defensive posture.
- An organization may have an extremely strong defensive posture, but that could completely change if new vulnerabilities are found that impact their operations.
- If an unknown vulnerability or threat is identified, the defensive posture may be weakened until adjustments are made to mitigate the new threat.
- Due to this, a need arises to integrate knowledge of new threats and vulnerabilities into operations.
- This process is called intelligence-driven Defensive Cyberspace Operations (DCO). 

- Intelligence-driven operations have always been an integral part of all operations in the U.S. Department of Defense (DoD), including DCO.
- In essence, the goal of intelligence-driven DCO is to leverage Cyber Threat Intelligence (CTI) to establish and strengthen the defensive posture of an organization.
- The understanding of threat actors and their techniques is key to building secure architecture and finding new detection measures for threats.
- Using intelligence-driven DCO minimizes risk and emboldens defensive posture.

### Implementing Intelligence in Operations
- Intelligence should be ingested into operations to adequately defend against known threats.
- Using intelligence, security analysts can **identify patch recommendations for known threats**, **devices that need additional security controls**, and **monitoring/alerting priorities**.
- When using CTI, cybersecurity personnel should gather an understanding of TTPs used by threat actors that are related to operations.
- Leveraging TTPs can help to identify areas where threat activity can be discovered and defensive measures can be implemented.
- Additionally, knowledge of TTPs can be used to create multiple defensive measures.
- Creating layered defenses for known threats can drastically improve defensive posture.
- When a new threat is identified, the ATT&CK framework can break down the individual phases of the attack.
- Using this knowledge, security controls can be implemented, altered, or created to increase defenses for the new threat.

### Deliberate Defense Posture
- Cyber Protection Teams (CPT) may need to establish a deliberate defense posture to adequately defend against adversary activity.
- In some instances of an engaged attack, threat actors may be in an area with poor visibility or network gaps that result in a weakened defensive posture and defensive capabilities.
- The CPT modifies the environment in cyberspace to disrupt actions in those areas and force threat actors into areas where CPTs have better visibility and capability to respond to threat actor activity.

### Securing Device Configs through CTI
- When analyzing any network, ensuring secure configurations on assets is a priority.
- Threat intelligence can provide even further insight into different vulnerabilities that are actively being exploited within an industry.
  - This can lead to prioritization of vulnerabilities over others due to a known active threat.

- Intelligence may direct that certain **ports**, **protocols**, **software**, and **devices** are part of a threat actor’s **TTPs**.
- This can lead to **immediate patching priorities** for these devices, **alterations to current configurations**, **creation of new alerting or response actions**, or even **removal of devices**.
- In some cases, recently patched or upgraded devices may be the target of a newfound threat. This can lead to rolling back to previous versions that had fewer security issues if it is deemed safer for operations.

### Establishing Monitoring Priorities with CTI
- SIEMs can be used to implement intelligence directly into operations by creating specific searches and alerts that monitor for cyber threats found through intelligence.
- Through root cause analysis of malicious activity, specific alerts and monitoring capabilities are generated to avoid repeat offense of this activity.
- Leveraging SIEM tools, intelligence can be used to drive the creation of new searches and alerts as soon as threats become known.

- Additionally, (**IDS**) and (**IPS**) can be used to create or highlight alerts that monitor for specific threats that have been identified through intelligence.
- These systems use signatures for known threats that create a log or block traffic if the signature’s requirements are met.
- The signatures generally look for specific traffic patterns or file accesses that are associated with known malicious activity.
- They can generate false positives as well, which means the system needs to be tuned and catered to each organization’s architecture.

- Many SIEM and IDS/IPS tools have intelligence capabilities that allow them to connect to a CTI feed.
- These provided threat feeds can be used to ingest known alerts or searches to identify new or previously unidentified threats or capabilities of threat actors.
- CTI feeds are great solutions for organizations that may not have an internal intelligence capability.
- However, integrated CTI feeds are often a paid service, so organizational leadership must determine if this method is worthwhile.

### Training with CTI
- Personnel within an organization are always at risk of being targeted by an attack from social engineering, phishing, and similar attacks.
- Developing training in conjunction with threat intelligence can help to keep personnel informed of possible threats that may affect an organization.
- If an organization is at risk of being attacked by a specific APT, then training should be made showcasing their attack methods and how these threats could be directed toward the organization.
- Using this intelligence in training is a critical portion of increasing the defensive posture of an organization.





